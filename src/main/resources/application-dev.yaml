server:
  port: 8080

pentaho:
  web-target: http://localhost:8080
  username: cluster
  password: cluster

directory:
  path: C:\test2
  target: C:\
  #原始csv存放目錄
  receive-file-dir: /home/addr/batch_data/receive/
  #批次zip檔存放目錄
  send-file-dir: /home/addr/batch_data/send/
  big-data-receive-file-dir: /home/addr/big_data/receive/
  big-data-send-file-dir: /home/addr/big_data/send/
  local-temp-dir: D:\temp\
  #  etl作業產出的檔案位置前綴
  etl-output-file-dir-prefix: D:\home\ec2-user\test222\
  # 模擬聖森存檔案
  mock-etl-save-file-dir-prefix: D:\home\ec2-user\saveFile\
  # etl .ktr檔的存放位置
  ktr-file-path: D:\home\addr\prod\

#如果是自己要在 aws api server上測試，要改成rsa.pub(用自己的公鑰)
key:
  pubkey-name: D:\rsa_key\jwt.pub    #聖森公鑰
  ap-prikey-name: D:\rsa_key\rsa.pri #AP私鑰
  ap-pubkey-name: D:\rsa_key\rsa.pub #AP公鑰

apserver:
  #  批次查詢: 聖森接收批次結束檔案的api url
  target-url: http://211.75.133.17:7007/addr/api/auth/batchForm/systemUpdate
  token: D:\token\token.txt

spring:
  data:
    redis:
      database: 0
      host: 34.211.215.66
      port: 8005
      # Redis密碼，默認為空
      password:
  datasource:
    jdbc-url: jdbc:vertica://52.40.252.111:5433/vdb
    username: dbadmin
    password: 1qaz@WSX
    driver-class-name: com.vertica.jdbc.Driver
    hikari:
      driver-class-name: io.opentracing.contrib.jdbc.TracingDriver
      jdbc-url: jdbc:vertica://52.40.252.111:5433/vdb
      poolName: Hikari
      auto-commit: false
      data-source-properties:
        cachePrepStmts: true
        prepStmtCacheSize: 250
        prepStmtCacheSqlLimit: 2048

sftputils:
  host: 52.33.116.195
  port: 22
  username: ubuntu
  private-key: D:\moi_key\moi-addr-privatekey.pem
